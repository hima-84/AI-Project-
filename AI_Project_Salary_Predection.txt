 # %%
import pandas as pd # display data frame (to et3aml with excel files)
import numpy as np # edit in data frame and numeric operations
import seaborn as sns # visualise the data like (pear plot(to know corilations))
import matplotlib.pyplot as plt # like seaborn (box plot ,pie chart)
from sklearn.model_selection import train_test_split,cross_val_score 
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from matplotlib import cm #color maps
from sklearn.feature_selection import chi2, SelectKBest, f_classif
from sklearn.linear_model import LogisticRegression

from sklearn.svm import SVC
lol= pd.read_csv(r"max.csv") # read the excel files 
kn= pd.read_csv(r"rfc.csv") # read the excel files 

df= pd.read_csv(r"Dataset.csv") # read the excel files 


# %%

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import roc_auc_score
from sklearn import metrics
import statistics
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV


# %%
from sklearn import metrics
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score

#nltk.download('stopwords')

# %%
import lazypredict
from lazypredict.Supervised import LazyClassifier

# %%
df.info() # shows the data frame info 

# %%
kn['salary']=kn['salary'].replace([1],' <=50K')
kn['salary']=kn['salary'].replace([0],' >50K')


kn.to_csv("rffcc.csv")

# %%
kn

# %%
df

# %%

display(df.describe(include="object")) #df.describe (describe numric datas only ) / include all describe all the data/ df.describe(include="objects ")describe all objects
display(df.describe())

# %% [markdown]
# change data form range or discreat to 0 & 1
# 

# %%
df['salary']=df['salary'].replace([' <=50K'],'1')
df['salary']=df['salary'].replace([' >50K'],'0')
df['sex']=df['sex'].replace([' Female'],'1')
df['sex']=df['sex'].replace([' Male'],'0')#replace data to 0 and 1

# %% [markdown]
# label enccoder to change objects to numbers to make it possiple to study the data

# %%
label_encoder=LabelEncoder()
df['salary']=label_encoder.fit_transform(df['salary'])
df['education']=label_encoder.fit_transform(df['education'])
df['relationship']=label_encoder.fit_transform(df['relationship'])
df['race']=label_encoder.fit_transform(df['race'])
df['sex']=label_encoder.fit_transform(df['sex'])
df['education']=label_encoder.fit_transform(df['education'])
df['native-country']=label_encoder.fit_transform(df['native-country'])
df['position']=label_encoder.fit_transform(df['position'])
df['work-class']=label_encoder.fit_transform(df['work-class'])
df['marital-status']=label_encoder.fit_transform(df['marital-status'])#change catigoral data to numiric

# %% [markdown]
# change the missing data to null 
# 

# %%
df["work-class"]=np.where(df["work-class"]==" ?",np.nan,df["work-class"])#["collumn name"]=np.where(df["collomn name "(if value of)]=="what i wanna change",change to,(else dont change) )
df["education"]=np.where(df["education"]==" ?",np.nan,df["education"])
df["marital-status"]=np.where(df["marital-status"]==" ?",np.nan,df["marital-status"])
df["position"]=np.where(df["position"]==" ?",np.nan,df["position"])
df["relationship"]=np.where(df["relationship"]==" ?",np.nan,df["relationship"])
df["race"]=np.where(df["race"]==" ?",np.nan,df["race"])
df["sex"]=np.where(df["sex"]==" ?",np.nan,df["sex"])
df["native-country"]=np.where(df["native-country"]==" ?",np.nan,df["native-country"])
df["salary"]=np.where(df["salary"]==" ?",np.nan,df["salary"])
df['capital-gain']=np.where(df['capital-gain']==0,df['capital-gain'].mean(),df['capital-gain'])#changed all the 0 to mean 
df['capital-loss']=np.where(df['capital-loss']==0,df['capital-loss'].mean(),df['capital-loss'])

# %%
df.info()
df.drop(['work-fnl'],axis=1)

# %%
df

# %% [markdown]
# corrlation

# %%
print(df.corr())
#corrlation 
sns.heatmap(df.corr())
#heat map of corrlation

# %% [markdown]
# removed coloms with law corr

# %%
df.drop(['native-country'],axis=1,inplace=True)
df.drop(['race'],axis=1,inplace=True)
df.drop(['marital-status'],axis=1,inplace=True)
df.drop(['education'],axis=1,inplace=True)
df.drop(['work-fnl'],axis=1,inplace=True)
df.drop(['age'],axis=1,inplace=True)


#drop colomn with low corrliation
df



# %% [markdown]
# removed the null rows

# %%
pew=df.dropna().reset_index()#remove all null rows.reset df as new one without na
pew=pew.drop(labels=["index"],axis=1)#remove collomn=['collomn name'],axis=1(cause collumn )0 if row 


# %%
pew.shape
#number of rows and colom
pew



# %% [markdown]
# knn model begin
# 

# %%
Xk_train, Xk_test, Yk_train, Yk_test = train_test_split(pew.iloc[:,:8], pew.salary, random_state = 42,test_size=0.3)
#split data to test and train[allrows,from colom 0 to 9 ],prdiction variable,shufle 42 times 30%test 
knn = KNeighborsClassifier(n_neighbors = 2)
#2 catigories (0 and 1 )for salary
knn.fit(Xk_train, Yk_train)
Yk_pred = knn.predict(Xk_test)
accuracy_score(Yk_test, Yk_pred)


# %%
ypred=knn.predict(Xk_train)
accuracy_score(Yk_train, ypred)


# %%
grid_params = { 'n_neighbors' : [5,7,9,11,13,15],
               'weights' : ['uniform','distance'],
               'metric' : ['minkowski','euclidean','manhattan']}

# %%
gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)
g_res = gs.fit(Xk_train, Yk_train)


# %%
g_res.best_score_

# %%
g_res.best_params_

# %%
knn = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform',algorithm = 'brute',metric = 'minkowski')
knn.fit(Xk_train, Yk_train)

# %%
# get a prediction
y_hat = knn.predict(Xk_train)
y_knn = knn.predict(Xk_test)

# %%
print('Training set accuracy: ', metrics.accuracy_score(Yk_train, y_hat))
print('Test set accuracy: ',metrics.accuracy_score(Yk_test, y_knn))

# %%

Y_pred_KNN2 = knn.predict(lol)
lol["salary"]=Y_pred_KNN2
lol.to_csv("knn.csv")


# %% [markdown]
# knn end

# %% [markdown]
# standerization make all number on the same range to have equal importance
# 

# %%
#standerization make all number on the same range to have equal importance
yrf=pew['salary']#LABEL
xrf=pew.drop(columns='salary')#FEATURES
def listOflists(lst):
    return [[el] for el in lst]
def flatten(t):
    return [item for sublist in t for item in sublist]
s=StandardScaler()
pew['education-num']=flatten(s.fit_transform(listOflists(pew['education-num'].to_numpy().tolist())))
pew['hours-per-week']=flatten(s.fit_transform(listOflists(pew['hours-per-week'].to_numpy().tolist())))
pew['capital-gain']=flatten(s.fit_transform(listOflists(pew['capital-gain'].to_numpy().tolist())))
pew['capital-loss']=flatten(s.fit_transform(listOflists(pew['capital-loss'].to_numpy().tolist())))

sm = SMOTE(random_state=42)#to deal with unbalanced data
x_res, y_res = sm.fit_resample(xrf,yrf)

# %% [markdown]
# start random forst

# %%
xrf_train,xrf_test,yrf_train,yrf_test=train_test_split(x_res,y_res,test_size=0.2,random_state=42,shuffle=True)#random state:to get the same result every time you run the code
                            #CREATING AN INSTANCE OF RANDOM FOREST CLASSIFIER#
rfc=RandomForestClassifier(random_state=42,class_weight='balanced',max_depth=25,n_estimators=300,max_features='sqrt')
rfc.fit(x_res,y_res)


# %%
rfcpp=rfc.predict(lol)
lol["salary"]=rfcpp
lol.to_csv("rfc.csv")

# %%
                        #CROSS VALIDATION#
"""cross_val_score(rfc, x_res, y_res, cv=5, scoring='accuracy')
accuracy = np.array(cross_val_score(rfc, x_res, y_res, cv=5, scoring='accuracy'))
print(accuracy)
print(accuracy.mean())"""

# %%
                         #CHOOSING HYPERPARAMETERS#
"""RandomForestClassifier().get_params()#display random forest hyper parameters
n_estimators_list=list(range(200,350,50))
max_depth_list=list(range(5,30,10))
params_grid={'n_estimators':n_estimators_list,'max_depth':max_depth_list}
num_combinations=1
for k in params_grid.keys():num_combinations*=len(params_grid[k])
print('num of combinations = ',num_combinations)
print(params_grid)
def my_roc_auc_score(model,x_res,y_res):return metrics.roc_auc_score(y_res,model.predict(x_res))
rfc=GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),param_grid=params_grid,cv=5,scoring=my_roc_auc_score,return_train_score=True,verbose=4)
#rfc=RandomizedSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),param_distributions=params_grid,cv=3,scoring=my_roc_auc_score,return_train_score=True,verbose=2)
rfc.fit(x_res,y_res)

print(rfc.best_params_)#display best combination of parameters"""

# %% [markdown]
# end random forst

# %% [markdown]
# start svm

# %%
training_set, test_set = train_test_split(pew, test_size = 0.3, random_state = 42)
Xs_train = training_set.iloc[:,0:7].values
Ys_train = training_set.iloc[:,8].values
Xs_test = test_set.iloc[:,0:7].values
Ys_test = test_set.iloc[:,8].values

# %%
classifier = SVC(kernel='rbf', random_state = 42)
classifier.fit(Xs_train,Ys_train)
Y_pred = classifier.predict(Xs_test)
test_set["Predictions"] = Y_pred
cm = confusion_matrix(Ys_test,Y_pred)
accuracy = float(cm.diagonal().sum())/len(Ys_test)
accuracyt = float(cm.diagonal().sum())/len(Ys_train)
print("\nAccuracy Of SVM For The Given Dataset : ", accuracy)
print("\nAccuracy Of SVM For The Given Dataset tt: ", accuracyt)


# %% [markdown]
# end svm

# %% [markdown]
# start logistics

# %%
# to compare our model's accuracy with sklearn model
# Logistic Regression
class LogitRegression() :
	def __init__( self, learning_rate, iterations ) :		
		self.learning_rate = learning_rate		
		self.iterations = iterations
		
	# Function for model training	
	def fit( self, X, Y ) :		
		# no_of_training_examples, no_of_features		
		self.m, self.n = X.shape		
		# weight initialization		
		self.W = np.zeros( self.n )		
		self.b = 0		
		self.X = X		
		self.Y = Y
		
		# gradient descent learning
				
		for i in range( self.iterations ) :			
			self.update_weights()			
		return self
	
	# Helper function to update weights in gradient descent
	
	def update_weights( self ) :		
		A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )
		
		# calculate gradients		
		tmp = ( A - self.Y.T )		
		tmp = np.reshape( tmp, self.m )		
		dW = np.dot( self.X.T, tmp ) / self.m		
		db = np.sum( tmp ) / self.m
		
		# update weights	
		self.W = self.W - self.learning_rate * dW	
		self.b = self.b - self.learning_rate * db
		
		return self
	
	# Hypothetical function h( x )
	
	def predict( self, X ) :	
		Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )		
		Y = np.where( Z > 0.5, 1, 0 )		
		return Y


# Driver code

def main() :
	
	# Importing dataset	
	df = pd.read_csv( "datasecondedition.csv" )
	X = df.iloc[:,:-1].values
	Y = df.iloc[:,-1:].values
	
	# Splitting dataset into train and test set
	X_train, X_test, Y_train, Y_test = train_test_split(
	X, Y, test_size = 1/3, random_state = 0 )
	
	# Model training	
	model = LogitRegression( learning_rate = 0.01, iterations = 1000 )
	
	model.fit( X_train, Y_train )	
	model1 = LogisticRegression()	
	model1.fit( X_train, Y_train)
	
	# Prediction on test set
	Y_pred = model.predict( X_test )	
	Y_pred1 = model1.predict( X_test )
	
	# measure performance	
	correctly_classified = 0	
	correctly_classified1 = 0
	
	# counter	
	count = 0	
	for count in range( np.size( Y_pred ) ) :
		
		if Y_test[count] == Y_pred[count] :			
			correctly_classified = correctly_classified + 1
		
		if Y_test[count] == Y_pred1[count] :			
			correctly_classified1 = correctly_classified1 + 1
			
		count = count + 1
		
	print( "Accuracy on test set by our model	 : ", (
	correctly_classified / count ) * 100 )
	print( "Accuracy on test set by sklearn model : ", (
	correctly_classified1 / count ) * 100 )
	if __name__ == "__main__" :
    	 main()



# %%
#DecisionTreeClassifier
Xd_train, Xd_test, Yd_train, Yd_test = train_test_split(pew.iloc[:,:8], pew.salary, random_state = 42,test_size=0.3)

dt = DecisionTreeClassifier()
dt = dt.fit(Xd_train,Yd_train)
y_pred = dt.predict(Xd_test)
print("Usin DT:")
print(metrics.accuracy_score(Yd_test, y_pred))



